{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tslearn nilearn\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import tarfile\n",
        "import gc # For garbage collection and memory management\n",
        "import matplotlib.cm as cm # For colormap handling\n",
        "import pandas as pd # For saving to CSV\n",
        "\n",
        "# Nilearn for brain image plotting and datasets\n",
        "from nilearn import plotting, datasets\n",
        "\n",
        "# tslearn for K-Means clustering (DTW K-Means)\n",
        "from tslearn.clustering import TimeSeriesKMeans\n",
        "from tslearn.barycenters import dtw_barycenter_averaging\n",
        "\n",
        "# --- Basic parameters ---\n",
        "HCP_DIR = \"./DATA\" # Directory to store downloaded and extracted HCP data\n",
        "plots_output_dir = \"./brain_plots\" # Directory to store generated plots\n",
        "csv_output_dir = \"./csv_data\" # Directory to store generated CSV files\n",
        "\n",
        "# Ensure directories exist\n",
        "if not os.path.isdir(HCP_DIR):\n",
        "    os.mkdir(HCP_DIR)\n",
        "    print(f\"Created data directory: {HCP_DIR}\")\n",
        "\n",
        "if not os.path.isdir(plots_output_dir):\n",
        "    os.mkdir(plots_output_dir)\n",
        "    print(f\"Created plots output directory: {plots_output_dir}\")\n",
        "\n",
        "if not os.path.isdir(csv_output_dir):\n",
        "    os.mkdir(csv_output_dir)\n",
        "    print(f\"Created CSV output directory: {csv_output_dir}\")\n",
        "\n",
        "print(f\"Brain plots will be saved to: {plots_output_dir}\")\n",
        "print(f\"CSV data will be saved to: {csv_output_dir}\")\n",
        "\n",
        "N_PARCELS = 360 # Number of parcels in the Glasser Atlas\n",
        "TR = 0.72 # Repetition Time (TR) for HCP fMRI data\n",
        "N_RUNS_REST = 4 # Number of resting-state runs per subject\n",
        "N_SUBJECTS_FOR_GROUP_ANALYSIS = 100 # How many subjects to include in the group average (for K-means on brain states)\n",
        "\n",
        "# BOLD run names (only need resting state for this analysis)\n",
        "BOLD_NAMES = [\n",
        "    \"rfMRI_REST1_LR\", \"rfMRI_REST1_RL\",\n",
        "    \"rfMRI_REST2_LR\", \"rfMRI_REST2_RL\",\n",
        "]\n",
        "\n",
        "# --- Download and Extract Data ---\n",
        "print(\"\\n--- Checking and downloading necessary data files ---\")\n",
        "# Only need hcp_rest.tgz and atlas.npz for this specific request\n",
        "fnames_to_check = [\"hcp_rest.tgz\", \"atlas.npz\"]\n",
        "urls_to_check = {\n",
        "    \"hcp_rest.tgz\": \"https://osf.io/bqp7m/download\",\n",
        "    \"atlas.npz\": \"https://osf.io/j5kuc/download\"\n",
        "}\n",
        "\n",
        "for fname in fnames_to_check:\n",
        "    url = urls_to_check.get(fname)\n",
        "    if not url:\n",
        "        print(f\"Error: URL for {fname} not found in urls_to_check map. Skipping download.\")\n",
        "        continue\n",
        "\n",
        "    if not os.path.isfile(fname):\n",
        "        try:\n",
        "            print(f\"Downloading {fname} from {url}...\")\n",
        "            r = requests.get(url, stream=True)\n",
        "            r.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"!!! Failed to download {fname}: {e} !!! Please check your internet connection or URL.\")\n",
        "        else:\n",
        "            with open(fname, \"wb\") as fid:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    fid.write(chunk)\n",
        "            print(f\"Download of {fname} completed!\")\n",
        "    else:\n",
        "        print(f\"'{fname}' already exists, skipping download.\")\n",
        "\n",
        "print(\"\\n--- Extracting data ---\")\n",
        "extraction_targets = {\n",
        "    \"hcp_rest.tgz\": os.path.join(HCP_DIR, \"hcp_rest\"),\n",
        "}\n",
        "\n",
        "for tgz_file, extract_dir in extraction_targets.items():\n",
        "    if os.path.isfile(tgz_file):\n",
        "        if not os.path.exists(extract_dir):\n",
        "            print(f\"Extracting {tgz_file} to {extract_dir}...\")\n",
        "            try:\n",
        "                with tarfile.open(tgz_file, \"r:gz\") as tar:\n",
        "                    tar.extractall(path=HCP_DIR)\n",
        "                print(f\"Extraction of {tgz_file} completed!\")\n",
        "            except tarfile.ReadError as e:\n",
        "                print(f\"!!! Failed to extract {tgz_file}: {e} !!! Ensure download was complete/not corrupted.\")\n",
        "        else:\n",
        "            print(f\"{extract_dir} already exists, skipping extraction for {tgz_file}.\")\n",
        "    else:\n",
        "        print(f\"'{tgz_file}' not found, skipping extraction.\")\n",
        "\n",
        "# --- Load Atlas Information and fsaverage surface ---\n",
        "print(\"\\n--- Loading atlas and fsaverage surface information ---\")\n",
        "\n",
        "try:\n",
        "    with np.load(\"atlas.npz\") as dobj:\n",
        "        atlas = dict(**dobj)\n",
        "    print(\"Atlas information (Glasser parcels and hemisphere labels) loaded.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: atlas.npz not found. Please ensure it is in the current directory or downloaded.\")\n",
        "    exit()\n",
        "\n",
        "fsaverage = datasets.fetch_surf_fsaverage()\n",
        "print(\"fsaverage surface data loaded.\")\n",
        "\n",
        "\n",
        "# --- Helper functions ---\n",
        "def get_image_ids(name):\n",
        "    \"\"\"\n",
        "    Returns the BOLD run IDs for a given task/rest name.\n",
        "    \"\"\"\n",
        "    run_ids = [i for i, code in enumerate(BOLD_NAMES, 1) if name.upper() in code]\n",
        "    if not run_ids:\n",
        "        raise ValueError(f\"Found no data for '{name}'\")\n",
        "    return run_ids\n",
        "\n",
        "def load_single_timeseries(subject, bold_run, dir, remove_mean=True):\n",
        "    \"\"\"\n",
        "    Loads a single BOLD time series for a given subject and run.\n",
        "    \"\"\"\n",
        "    bold_path = os.path.join(dir, \"subjects\", str(subject), \"timeseries\")\n",
        "    bold_file = f\"bold{bold_run}_Atlas_MSMAll_Glasser360Cortical.npy\"\n",
        "    ts = np.load(os.path.join(bold_path, bold_file))\n",
        "    if remove_mean:\n",
        "        ts -= ts.mean(axis=1, keepdims=True)\n",
        "    return ts\n",
        "\n",
        "def load_timeseries(subject, name, dir, runs=None, concat=True, remove_mean=True):\n",
        "    \"\"\"\n",
        "    Loads and optionally concatenates multiple BOLD time series for a subject and condition.\n",
        "    \"\"\"\n",
        "    if runs is None:\n",
        "        runs_count = N_RUNS_REST # Only resting state for this analysis\n",
        "        runs = range(runs_count)\n",
        "    elif isinstance(runs, int):\n",
        "        runs = [runs]\n",
        "\n",
        "    offset = get_image_ids(name)[0]\n",
        "\n",
        "    bold_data = [load_single_timeseries(subject, offset + run, dir, remove_mean) for run in runs]\n",
        "\n",
        "    if concat:\n",
        "        bold_data = np.concatenate(bold_data, axis=-1)\n",
        "    return bold_data\n",
        "\n",
        "# --- End Helper Functions ---\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "#                                 MAIN ANALYSIS:                               #\n",
        "#        K-Means Clustering on Subject-Level Resting-State Brain States        #\n",
        "##################################################################################\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"Starting K-Means Clustering on Resting-State Brain States for {N_SUBJECTS_FOR_GROUP_ANALYSIS} Subjects\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Parameters for K-Means Clustering on Resting States\n",
        "chosen_k = 3 # Number of clusters (kernels)\n",
        "\n",
        "resting_state_data_dir = os.path.join(HCP_DIR, \"hcp_rest\")\n",
        "\n",
        "print(f\"Collecting resting-state brain states for the first {N_SUBJECTS_FOR_GROUP_ANALYSIS} subjects...\")\n",
        "\n",
        "all_subjects_resting_brain_states = []\n",
        "\n",
        "for subject_idx in range(N_SUBJECTS_FOR_GROUP_ANALYSIS):\n",
        "    # print(f\"  Processing Subject {subject_idx}...\") # Uncomment for detailed progress\n",
        "    try:\n",
        "        ts_rest_subject = load_timeseries(subject=subject_idx,\n",
        "                                          name=\"rest\",\n",
        "                                          dir=resting_state_data_dir,\n",
        "                                          concat=True,\n",
        "                                          remove_mean=True)\n",
        "\n",
        "        brain_state_subject = np.mean(ts_rest_subject, axis=1) # Average over time to get a single brain state per parcel for the subject\n",
        "        all_subjects_resting_brain_states.append(brain_state_subject)\n",
        "\n",
        "        del ts_rest_subject, brain_state_subject\n",
        "        gc.collect()\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"    Warning: Resting-state data not found for Subject {subject_idx} at {os.path.join(resting_state_data_dir, 'subjects', str(subject_idx))}. Skipping this subject.\")\n",
        "        continue\n",
        "    except Exception as e:\n",
        "        print(f\"    Error processing Subject {subject_idx}: {e}. Skipping this subject.\")\n",
        "        continue\n",
        "\n",
        "if not all_subjects_resting_brain_states:\n",
        "    print(\"No subjects were successfully processed for K-Means analysis. Please check data paths and files.\")\n",
        "else:\n",
        "    # Convert list of brain states to a NumPy array for clustering\n",
        "    # Shape will be (N_SUBJECTS, N_PARCELS)\n",
        "    all_subjects_resting_brain_states_array = np.array(all_subjects_resting_brain_states)\n",
        "    print(f\"Shape of collected subject-level brain states: {all_subjects_resting_brain_states_array.shape}\")\n",
        "\n",
        "    # For tslearn, data needs to be (n_samples, n_timestamps, n_features).\n",
        "    # Here, n_samples is N_SUBJECTS, n_timestamps is N_PARCELS, and n_features is 1 (univariate 'brain state' vector)\n",
        "    # The 'time' dimension for clustering is the parcels themselves.\n",
        "    resting_states_for_kmeans = all_subjects_resting_brain_states_array[:, :, np.newaxis]\n",
        "    print(f\"Shape of resting brain states for tslearn K-Means: {resting_states_for_kmeans.shape}\")\n",
        "\n",
        "    print(f\"\\nPerforming K-Means Clustering (k={chosen_k}) on {len(all_subjects_resting_brain_states)} subject resting brain states...\")\n",
        "\n",
        "    try:\n",
        "        km_rest = TimeSeriesKMeans(n_clusters=chosen_k, metric=\"dtw\", max_iter=10, random_state=0, verbose=False)\n",
        "        km_rest.fit(resting_states_for_kmeans)\n",
        "        print(\"  Clustering of subject resting states complete.\")\n",
        "\n",
        "        # Get cluster assignments for each subject\n",
        "        subject_clusters = km_rest.labels_\n",
        "        print(f\"Subject cluster assignments (labels_) shape: {subject_clusters.shape}\")\n",
        "        print(f\"Unique subject cluster IDs: {np.unique(subject_clusters)}\")\n",
        "\n",
        "        # Get the barycenters (mean brain state for each cluster of subjects)\n",
        "        # These barycenters represent the 'average' brain state for each identified cluster.\n",
        "        barycenters_rest = km_rest.cluster_centers_\n",
        "        barycenters_rest_reshaped = barycenters_rest.squeeze() # Remove the single-feature dimension\n",
        "        print(f\"Shape of barycenters (mean brain states for each cluster): {barycenters_rest_reshaped.shape}\")\n",
        "\n",
        "        # --- Plot Barycenter Brain States on Brain Surface ---\n",
        "        print(f\"\\nPlotting barycenter brain states for k={chosen_k} clusters...\")\n",
        "        try:\n",
        "            fig_bary_brains = plt.figure(figsize=(16, 4 * chosen_k))\n",
        "            fig_bary_brains.suptitle(f'Resting State Brain State Barycenters (k={chosen_k})', fontsize=16)\n",
        "\n",
        "            for i in range(chosen_k):\n",
        "                # The barycenter itself is a brain state (a 360-element vector)\n",
        "                current_barycenter_state = barycenters_rest_reshaped[i]\n",
        "\n",
        "                vabs_max_bary = np.max(np.abs(current_barycenter_state))\n",
        "                # Ensure the color range is not zero if all values are tiny\n",
        "                if vabs_max_bary == 0:\n",
        "                    vabs_max_bary = 1e-12 # Small non-zero value to prevent division by zero for colorbar\n",
        "                vmin_bary, vmax_bary = -vabs_max_bary, vabs_max_bary\n",
        "\n",
        "                # Left Hemisphere plot for current barycenter\n",
        "                ax_bary_left = fig_bary_brains.add_subplot(chosen_k, 2, i*2 + 1, projection='3d')\n",
        "                display_bary_left = plotting.plot_surf_stat_map(\n",
        "                    fsaverage['infl_left'],\n",
        "                    current_barycenter_state[atlas[\"labels_L\"]],\n",
        "                    hemi='left',\n",
        "                    view='lateral',\n",
        "                    cmap='cold_hot',\n",
        "                    colorbar=False,\n",
        "                    bg_map=fsaverage['sulc_left'],\n",
        "                    title=f'Barycenter {i} - Left',\n",
        "                    vmax=vmax_bary, vmin=vmin_bary,\n",
        "                    figure=fig_bary_brains,\n",
        "                    axes=ax_bary_left\n",
        "                )\n",
        "\n",
        "                # Right Hemisphere plot for current barycenter\n",
        "                ax_bary_right = fig_bary_brains.add_subplot(chosen_k, 2, i*2 + 2, projection='3d')\n",
        "                display_bary_right = plotting.plot_surf_stat_map(\n",
        "                    fsaverage['infl_right'],\n",
        "                    current_barycenter_state[atlas[\"labels_R\"]],\n",
        "                    hemi='right',\n",
        "                    view='lateral',\n",
        "                    cmap='cold_hot',\n",
        "                    colorbar=False,\n",
        "                    bg_map=fsaverage['sulc_right'],\n",
        "                    title=f'Barycenter {i} - Right',\n",
        "                    vmax=vmax_bary, vmin=vmin_bary,\n",
        "                    figure=fig_bary_brains,\n",
        "                    axes=ax_bary_right\n",
        "                )\n",
        "\n",
        "                # Add a colorbar for each row (pair of hemispheres)\n",
        "                # Position: [left, bottom, width, height]\n",
        "                # 'bottom' calculated to place it below each row of plots\n",
        "                # This setup gives individual colorbars for each barycenter, which is appropriate as their ranges might differ.\n",
        "                cbar_ax_bary = fig_bary_brains.add_axes([0.3, (chosen_k - i - 1) * (1/(chosen_k+0.5)) + 0.05, 0.4, 0.02]) # Adjusted position for each row\n",
        "                norm_bary = plt.Normalize(vmin=vmin_bary, vmax=vmax_bary)\n",
        "                sm_bary = cm.ScalarMappable(cmap='cold_hot', norm=norm_bary)\n",
        "                sm_bary.set_array([])\n",
        "                cbar_bary = fig_bary_brains.colorbar(sm_bary, cax=cbar_ax_bary, orientation='horizontal')\n",
        "                cbar_bary.set_label('Mean BOLD (Barycenter)')\n",
        "                cbar_bary.ax.tick_params(labelsize=8)\n",
        "\n",
        "            fig_bary_brains.subplots_adjust(left=0.01, right=0.99, top=0.95, bottom=0.01, hspace=0.3, wspace=0.05)\n",
        "            plt.savefig(os.path.join(plots_output_dir, f'resting_state_barycenter_brain_states_k{chosen_k}.png'))\n",
        "            plt.close(fig_bary_brains)\n",
        "            print(f\"Barycenter brain states plot saved to '{plots_output_dir}'.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error plotting barycenter brain states: {e}\")\n",
        "\n",
        "        # --- Save Barycenter Values to CSV ---\n",
        "        print(f\"\\nSaving barycenter values to CSV...\")\n",
        "        try:\n",
        "            # Create column names\n",
        "            column_names = [f'Barycenter_{i}' for i in range(chosen_k)]\n",
        "            # Create a DataFrame from the reshaped barycenters\n",
        "            # Each row is a parcel, each column is a barycenter\n",
        "            df_barycenters = pd.DataFrame(barycenters_rest_reshaped.T, columns=column_names)\n",
        "            # Add a column for Parcel ID if desired (0 to 359)\n",
        "            df_barycenters.index.name = 'Parcel_ID'\n",
        "\n",
        "            csv_file_path = os.path.join(csv_output_dir, f'resting_state_barycenters_k{chosen_k}.csv')\n",
        "            df_barycenters.to_csv(csv_file_path)\n",
        "            print(f\"Barycenter values saved to '{csv_file_path}'.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving barycenter values to CSV: {e}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  An error occurred during K-Means clustering of resting states: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"K-Means Clustering on Resting-State Brain States Completed.\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC9jL-U7I8hj",
        "outputId": "03e0ff85-5874-497f-9882-c7787097422c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tslearn in /usr/local/lib/python3.11/dist-packages (0.6.4)\n",
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.11/dist-packages (0.12.0)\n",
            "Requirement already satisfied: scikit-learn<1.7,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from tslearn) (1.6.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tslearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<1.17,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from tslearn) (1.16.0)\n",
            "Requirement already satisfied: numba<0.62,>=0.58.1 in /usr/local/lib/python3.11/dist-packages (from tslearn) (0.60.0)\n",
            "Requirement already satisfied: joblib<1.6,>=0.12 in /usr/local/lib/python3.11/dist-packages (from tslearn) (1.5.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from nilearn) (5.4.0)\n",
            "Requirement already satisfied: nibabel>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (5.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from nilearn) (25.0)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (2.32.3)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel>=5.2.0->nilearn) (6.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel>=5.2.0->nilearn) (4.14.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba<0.62,>=0.58.1->tslearn) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->nilearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->nilearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->nilearn) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (2025.7.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.7,>=1.3.2->tslearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->nilearn) (1.17.0)\n",
            "Created CSV output directory: ./csv_data\n",
            "Brain plots will be saved to: ./brain_plots\n",
            "CSV data will be saved to: ./csv_data\n",
            "\n",
            "--- Checking and downloading necessary data files ---\n",
            "'hcp_rest.tgz' already exists, skipping download.\n",
            "'atlas.npz' already exists, skipping download.\n",
            "\n",
            "--- Extracting data ---\n",
            "./DATA/hcp_rest already exists, skipping extraction for hcp_rest.tgz.\n",
            "\n",
            "--- Loading atlas and fsaverage surface information ---\n",
            "Atlas information (Glasser parcels and hemisphere labels) loaded.\n",
            "fsaverage surface data loaded.\n",
            "\n",
            "================================================================================\n",
            "Starting K-Means Clustering on Resting-State Brain States for 100 Subjects\n",
            "================================================================================\n",
            "\n",
            "Collecting resting-state brain states for the first 100 subjects...\n",
            "Shape of collected subject-level brain states: (100, 360)\n",
            "Shape of resting brain states for tslearn K-Means: (100, 360, 1)\n",
            "\n",
            "Performing K-Means Clustering (k=3) on 100 subject resting brain states...\n",
            "  Clustering of subject resting states complete.\n",
            "Subject cluster assignments (labels_) shape: (100,)\n",
            "Unique subject cluster IDs: [0 1 2]\n",
            "Shape of barycenters (mean brain states for each cluster): (3, 360)\n",
            "\n",
            "Plotting barycenter brain states for k=3 clusters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-139637799.py:248: DeprecationWarning: The `darkness` parameter will be deprecated in release 0.13. We recommend setting `darkness` to None\n",
            "  display_bary_left = plotting.plot_surf_stat_map(\n",
            "/tmp/ipython-input-13-139637799.py:264: DeprecationWarning: The `darkness` parameter will be deprecated in release 0.13. We recommend setting `darkness` to None\n",
            "  display_bary_right = plotting.plot_surf_stat_map(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Barycenter brain states plot saved to './brain_plots'.\n",
            "\n",
            "Saving barycenter values to CSV...\n",
            "Barycenter values saved to './csv_data/resting_state_barycenters_k3.csv'.\n",
            "\n",
            "================================================================================\n",
            "K-Means Clustering on Resting-State Brain States Completed.\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}